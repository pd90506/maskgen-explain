Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Predicted class: golden retriever

params to be optimized: 
['similarity_measure.logit_scale', 'similarity_measure.pred_map.input_layer.weight', 'similarity_measure.pred_map.input_layer.bias', 'similarity_measure.pred_map.layers.0.0.weight', 'similarity_measure.pred_map.layers.0.0.bias', 'similarity_measure.pred_map.layers.0.3.weight', 'similarity_measure.pred_map.layers.0.3.bias', 'similarity_measure.pred_map.layers.0.6.weight', 'similarity_measure.pred_map.layers.0.6.bias', 'similarity_measure.pred_map.layers.1.0.weight', 'similarity_measure.pred_map.layers.1.0.bias', 'similarity_measure.pred_map.layers.1.3.weight', 'similarity_measure.pred_map.layers.1.3.bias', 'similarity_measure.pred_map.layers.1.6.weight', 'similarity_measure.pred_map.layers.1.6.bias', 'similarity_measure.pred_map.output_layer.weight', 'similarity_measure.pred_map.output_layer.bias', 'similarity_measure.explain_map.input_layer.weight', 'similarity_measure.explain_map.input_layer.bias', 'similarity_measure.explain_map.layers.0.0.weight', 'similarity_measure.explain_map.layers.0.0.bias', 'similarity_measure.explain_map.layers.0.3.weight', 'similarity_measure.explain_map.layers.0.3.bias', 'similarity_measure.explain_map.layers.0.6.weight', 'similarity_measure.explain_map.layers.0.6.bias', 'similarity_measure.explain_map.layers.1.0.weight', 'similarity_measure.explain_map.layers.1.0.bias', 'similarity_measure.explain_map.layers.1.3.weight', 'similarity_measure.explain_map.layers.1.3.bias', 'similarity_measure.explain_map.layers.1.6.weight', 'similarity_measure.explain_map.layers.1.6.bias', 'similarity_measure.explain_map.output_layer.weight', 'similarity_measure.explain_map.output_layer.bias']
  0%|          | 0/196 [00:00<?, ?it/s]Epoch 1, Step 1: Loss = 0.4493, Reward Loss = -0.4256, Mask Loss = 0.8749 mask_mean = 0.4874 prob_mean = 0.5816 :   0%|          | 0/196 [00:24<?, ?it/s]2024-05-20 21:48:35,206 - INFO - Epoch 1, Step 1: Loss = 0.4493, Reward Loss = -0.4256, Mask Loss = 0.8749 mask_mean = 0.4874 prob_mean = 0.5816 
Epoch 1, Step 1: Loss = 0.4493, Reward Loss = -0.4256, Mask Loss = 0.8749 mask_mean = 0.4874 prob_mean = 0.5816 :   1%|          | 1/196 [00:32<1:45:59, 32.61s/it]Epoch 1, Step 2: Loss = 0.4083, Reward Loss = -0.4836, Mask Loss = 0.8919 mask_mean = 0.4815 prob_mean = 0.5980 :   1%|          | 1/196 [00:55<1:45:59, 32.61s/it]Epoch 1, Step 2: Loss = 0.4083, Reward Loss = -0.4836, Mask Loss = 0.8919 mask_mean = 0.4815 prob_mean = 0.5980 :   1%|          | 2/196 [00:55<1:26:58, 26.90s/it]Epoch 1, Step 3: Loss = 0.3493, Reward Loss = -0.4566, Mask Loss = 0.8059 mask_mean = 0.4764 prob_mean = 0.5529 :   1%|          | 2/196 [01:16<1:26:58, 26.90s/it]Epoch 1, Step 3: Loss = 0.3493, Reward Loss = -0.4566, Mask Loss = 0.8059 mask_mean = 0.4764 prob_mean = 0.5529 :   2%|▏         | 3/196 [01:16<1:17:49, 24.19s/it]Epoch 1, Step 4: Loss = 0.3283, Reward Loss = -0.4954, Mask Loss = 0.8237 mask_mean = 0.4681 prob_mean = 0.5735 :   2%|▏         | 3/196 [01:39<1:17:49, 24.19s/it]Epoch 1, Step 4: Loss = 0.3283, Reward Loss = -0.4954, Mask Loss = 0.8237 mask_mean = 0.4681 prob_mean = 0.5735 :   2%|▏         | 4/196 [01:39<1:15:50, 23.70s/it]Epoch 1, Step 5: Loss = 0.3335, Reward Loss = -0.5315, Mask Loss = 0.8650 mask_mean = 0.4669 prob_mean = 0.6010 :   2%|▏         | 4/196 [02:00<1:15:50, 23.70s/it]Epoch 1, Step 5: Loss = 0.3335, Reward Loss = -0.5315, Mask Loss = 0.8650 mask_mean = 0.4669 prob_mean = 0.6010 :   3%|▎         | 5/196 [02:00<1:12:19, 22.72s/it]Epoch 1, Step 6: Loss = 0.3375, Reward Loss = -0.5614, Mask Loss = 0.8989 mask_mean = 0.4669 prob_mean = 0.6196 :   3%|▎         | 5/196 [02:21<1:12:19, 22.72s/it]Epoch 1, Step 6: Loss = 0.3375, Reward Loss = -0.5614, Mask Loss = 0.8989 mask_mean = 0.4669 prob_mean = 0.6196 :   3%|▎         | 6/196 [02:21<1:10:03, 22.13s/it]Epoch 1, Step 7: Loss = 0.2844, Reward Loss = -0.5240, Mask Loss = 0.8084 mask_mean = 0.4602 prob_mean = 0.5692 :   3%|▎         | 6/196 [02:43<1:10:03, 22.13s/it]Epoch 1, Step 7: Loss = 0.2844, Reward Loss = -0.5240, Mask Loss = 0.8084 mask_mean = 0.4602 prob_mean = 0.5692 :   4%|▎         | 7/196 [02:43<1:09:43, 22.13s/it]Epoch 1, Step 8: Loss = 0.2562, Reward Loss = -0.5246, Mask Loss = 0.7807 mask_mean = 0.4535 prob_mean = 0.5601 :   4%|▎         | 7/196 [03:04<1:09:43, 22.13s/it]Epoch 1, Step 8: Loss = 0.2562, Reward Loss = -0.5246, Mask Loss = 0.7807 mask_mean = 0.4535 prob_mean = 0.5601 :   4%|▍         | 8/196 [03:04<1:08:22, 21.82s/it]Epoch 1, Step 9: Loss = 0.2462, Reward Loss = -0.5559, Mask Loss = 0.8021 mask_mean = 0.4519 prob_mean = 0.5813 :   4%|▍         | 8/196 [03:25<1:08:22, 21.82s/it]Epoch 1, Step 9: Loss = 0.2462, Reward Loss = -0.5559, Mask Loss = 0.8021 mask_mean = 0.4519 prob_mean = 0.5813 :   5%|▍         | 9/196 [03:25<1:07:27, 21.65s/it]Epoch 1, Step 10: Loss = 0.2324, Reward Loss = -0.5311, Mask Loss = 0.7635 mask_mean = 0.4454 prob_mean = 0.5591 :   5%|▍         | 9/196 [03:47<1:07:27, 21.65s/it]Epoch 1, Step 10: Loss = 0.2324, Reward Loss = -0.5311, Mask Loss = 0.7635 mask_mean = 0.4454 prob_mean = 0.5591 :   5%|▌         | 10/196 [03:47<1:07:00, 21.61s/it]Epoch 1, Step 11: Loss = 0.2032, Reward Loss = -0.5233, Mask Loss = 0.7265 mask_mean = 0.4394 prob_mean = 0.5440 :   5%|▌         | 10/196 [04:08<1:07:00, 21.61s/it]2024-05-20 21:52:19,521 - INFO - Epoch 1, Step 11: Loss = 0.2032, Reward Loss = -0.5233, Mask Loss = 0.7265 mask_mean = 0.4394 prob_mean = 0.5440 
Epoch 1, Step 11: Loss = 0.2032, Reward Loss = -0.5233, Mask Loss = 0.7265 mask_mean = 0.4394 prob_mean = 0.5440 :   6%|▌         | 11/196 [04:15<1:12:30, 23.51s/it]Epoch 1, Step 12: Loss = 0.1956, Reward Loss = -0.5064, Mask Loss = 0.7019 mask_mean = 0.4379 prob_mean = 0.5273 :   6%|▌         | 11/196 [04:36<1:12:30, 23.51s/it]Epoch 1, Step 12: Loss = 0.1956, Reward Loss = -0.5064, Mask Loss = 0.7019 mask_mean = 0.4379 prob_mean = 0.5273 :   6%|▌         | 12/196 [04:36<1:09:39, 22.72s/it]Epoch 1, Step 13: Loss = 0.1742, Reward Loss = -0.4957, Mask Loss = 0.6698 mask_mean = 0.4316 prob_mean = 0.5091 :   6%|▌         | 12/196 [04:58<1:09:39, 22.72s/it]Epoch 1, Step 13: Loss = 0.1742, Reward Loss = -0.4957, Mask Loss = 0.6698 mask_mean = 0.4316 prob_mean = 0.5091 :   7%|▋         | 13/196 [04:58<1:08:38, 22.51s/it]Epoch 1, Step 14: Loss = 0.1661, Reward Loss = -0.4717, Mask Loss = 0.6377 mask_mean = 0.4245 prob_mean = 0.4892 :   7%|▋         | 13/196 [05:19<1:08:38, 22.51s/it]Epoch 1, Step 14: Loss = 0.1661, Reward Loss = -0.4717, Mask Loss = 0.6377 mask_mean = 0.4245 prob_mean = 0.4892 :   7%|▋         | 14/196 [05:19<1:06:52, 22.05s/it]Epoch 1, Step 15: Loss = 0.1611, Reward Loss = -0.5369, Mask Loss = 0.6980 mask_mean = 0.4162 prob_mean = 0.5481 :   7%|▋         | 14/196 [05:40<1:06:52, 22.05s/it]Epoch 1, Step 15: Loss = 0.1611, Reward Loss = -0.5369, Mask Loss = 0.6980 mask_mean = 0.4162 prob_mean = 0.5481 :   8%|▊         | 15/196 [05:40<1:06:00, 21.88s/it]Epoch 1, Step 16: Loss = 0.1474, Reward Loss = -0.5019, Mask Loss = 0.6493 mask_mean = 0.4115 prob_mean = 0.5170 :   8%|▊         | 15/196 [06:01<1:06:00, 21.88s/it]Epoch 1, Step 16: Loss = 0.1474, Reward Loss = -0.5019, Mask Loss = 0.6493 mask_mean = 0.4115 prob_mean = 0.5170 :   8%|▊         | 16/196 [06:01<1:04:25, 21.47s/it]