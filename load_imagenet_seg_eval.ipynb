{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/crc/c/conda/23.5.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pixAcc: 0.8218, mIoU: 0.6679, mAP: 0.9033, mF1: 0.4778:   8%|â–Š         | 337/4276 [01:33<17:45,  3.70it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy import *\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from attvis.utils.metrices import *\n",
    "\n",
    "from attvis.utils import render\n",
    "from attvis.utils.saver import Saver\n",
    "from attvis.utils.iou import IoU\n",
    "\n",
    "from attvis.data.Imagenet import Imagenet_Segmentation\n",
    "from maskgen.models.random_mask import RandomMaskSaliency\n",
    "\n",
    "# from baselines.ViT.ViT_explanation_generator import Baselines, LRP\n",
    "# from baselines.ViT.ViT_new import vit_base_patch16_224\n",
    "# from baselines.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "# from baselines.ViT.ViT_orig_LRP import vit_base_patch16_224 as vit_orig_LRP\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "num_workers = 0\n",
    "batch_size = 1\n",
    "\n",
    "cls = ['airplane',\n",
    "       'bicycle',\n",
    "       'bird',\n",
    "       'boat',\n",
    "       'bottle',\n",
    "       'bus',\n",
    "       'car',\n",
    "       'cat',\n",
    "       'chair',\n",
    "       'cow',\n",
    "       'dining table',\n",
    "       'dog',\n",
    "       'horse',\n",
    "       'motobike',\n",
    "       'person',\n",
    "       'potted plant',\n",
    "       'sheep',\n",
    "       'sofa',\n",
    "       'train',\n",
    "       'tv'\n",
    "       ]\n",
    "\n",
    "alpha = 2\n",
    "\n",
    "imagenet_seg_path = \"data/gtsegs_ijcv.mat\"\n",
    "# method = 'ig'\n",
    "# method = 'rise'\n",
    "# method = 'random'\n",
    "method = 'ours'\n",
    "thr = 0.\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "\n",
    "# Data\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "test_img_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_lbl_trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224), Image.NEAREST),\n",
    "])\n",
    "\n",
    "ds = Imagenet_Segmentation(imagenet_seg_path,\n",
    "                           transform=test_img_trans, target_transform=test_lbl_trans)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "# # Model\n",
    "# model = vit_base_patch16_224(pretrained=True).cuda()\n",
    "# baselines = Baselines(model)\n",
    "\n",
    "# # LRP\n",
    "# model_LRP = vit_LRP(pretrained=True).cuda()\n",
    "# model_LRP.eval()\n",
    "# lrp = LRP(model_LRP)\n",
    "\n",
    "# # orig LRP\n",
    "# model_orig_LRP = vit_orig_LRP(pretrained=True).cuda()\n",
    "# model_orig_LRP.eval()\n",
    "# orig_lrp = LRP(model_orig_LRP)\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, ViTModel, ViTConfig, TrainingArguments, Trainer\n",
    "\n",
    "pretrained_name = 'google/vit-base-patch16-224'\n",
    "# pretrained_name = 'vit-base-patch16-224-finetuned-imageneteval'\n",
    "# pretrained_name = 'openai/clip-vit-base-patch32'\n",
    "config = ViTConfig.from_pretrained(pretrained_name)\n",
    "processor = ViTImageProcessor.from_pretrained(pretrained_name)\n",
    "# get mean and std to unnormalize the processed images\n",
    "mean, std = processor.image_mean, processor.image_std\n",
    "\n",
    "pred_model = ViTForImageClassification.from_pretrained(pretrained_name)\n",
    "pred_model.to(device)\n",
    "\n",
    "model = lambda x: pred_model(pixel_values=x).logits\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "ig = IntegratedGradients(lambda x: torch.softmax(pred_model(pixel_values=x).logits, dim=-1))\n",
    "\n",
    "random_mask = RandomMaskSaliency(model, num_classes=1000)\n",
    "\n",
    "from maskgen.models.vision_maskgen_model9 import MaskGeneratingModel\n",
    "\n",
    "mask_gen_model = MaskGeneratingModel(pred_model, hidden_size=config.hidden_size, num_classes=config.num_labels)\n",
    "mask_gen_model.to(device)\n",
    "# mask_gen_model.load_state_dict(torch.load('trained/vision_maskgen_model3/mask_gen_model_2_90.pth'))\n",
    "# mask_gen_model.load_state_dict(torch.load('mask_gen_model/mask_gen_model_final_9_195.pth'))\n",
    "mask_gen_model.load_state_dict(torch.load('mask_gen_model/mask_gen_model_1_150.pth'))\n",
    "# mask_gen_model.load_state_dict(torch.load('trained/mask_gen_model12/mask_gen_model_2_90.pth'))\n",
    "mask_gen_model.eval()\n",
    "\n",
    "\n",
    "metric = IoU(2, ignore_index=-1)\n",
    "\n",
    "iterator = tqdm(dl)\n",
    "\n",
    "pred_model.eval()\n",
    "\n",
    "\n",
    "def compute_pred(output):\n",
    "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "    # pred[0, 0] = 282\n",
    "    # print('Pred cls : ' + str(pred))\n",
    "    T = pred.squeeze().cpu().numpy()\n",
    "    T = np.expand_dims(T, 0)\n",
    "    T = (T[:, np.newaxis] == np.arange(1000)) * 1.0\n",
    "    T = torch.from_numpy(T).type(torch.FloatTensor)\n",
    "    Tt = T.cuda()\n",
    "\n",
    "    return Tt\n",
    "\n",
    "\n",
    "def eval_batch(image, labels, evaluator, index):\n",
    "    # evaluator.zero_grad()\n",
    "    # Save input image\n",
    "    # if args.save_img:\n",
    "    #     img = image[0].permute(1, 2, 0).data.cpu().numpy()\n",
    "    #     img = 255 * (img - img.min()) / (img.max() - img.min())\n",
    "    #     img = img.astype('uint8')\n",
    "    #     Image.fromarray(img, 'RGB').save(os.path.join(saver.results_dir, 'input/{}_input.png'.format(index)))\n",
    "    #     Image.fromarray((labels.repeat(3, 1, 1).permute(1, 2, 0).data.cpu().numpy() * 255).astype('uint8'), 'RGB').save(\n",
    "    #         os.path.join(saver.results_dir, 'input/{}_mask.png'.format(index)))\n",
    "\n",
    "    image.requires_grad = True\n",
    "    # print(\"image\", image.shape)\n",
    "\n",
    "    image = image.requires_grad_()\n",
    "    logits = evaluator(image) #.logits\n",
    "\n",
    "    # outputs = pred_model(image, output_hidden_states=True)\n",
    "    # logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    # print(\"predicted_class_idx\", predicted_class_idx)\n",
    "    \n",
    "    # segmentation test for the rollout baseline\n",
    "    if method == 'ig':\n",
    "        # Res = baselines.generate_rollout(image.cuda(), start_layer=1).reshape(batch_size, 1, 14, 14)\n",
    "        Res = ig.attribute(image.cuda(), target=predicted_class_idx, n_steps=200).sum(dim=1)\n",
    "        Res =  F.avg_pool2d(Res, kernel_size=16, stride=16)\n",
    "        # print(\"Res\",Res.shape)\n",
    "        Res = Res.reshape(batch_size, 1, 14, 14)\n",
    "\n",
    "    elif method == \"rise\":\n",
    "        Res = random_mask.attribute_img(image.cuda(),\n",
    "                                image_size=config.image_size, \n",
    "                                patch_size=config.patch_size, \n",
    "                                n_samples=100, \n",
    "                                mask_prob=0.5)\n",
    "        Res = Res.reshape(batch_size, 1, 14, 14)\n",
    "    \n",
    "    elif method == 'ours':\n",
    "        Res = mask_gen_model.attribute_img(image.cuda()).reshape(batch_size, 1, 14, 14)\n",
    "\n",
    "    elif method == \"random\":\n",
    "        Res = torch.rand(batch_size, 1, 14, 14).cuda()\n",
    "\n",
    "\n",
    "    if method != 'full_lrp':\n",
    "        # interpolate to full image size (224,224)\n",
    "        Res = torch.nn.functional.interpolate(Res, scale_factor=16, mode='bilinear').cuda()\n",
    "    \n",
    "    # threshold between FG and BG is the mean    \n",
    "    Res = (Res - Res.min()) / (Res.max() - Res.min())\n",
    "\n",
    "    ret = Res.mean()\n",
    "\n",
    "    Res_1 = Res.gt(ret).type(Res.type())\n",
    "    Res_0 = Res.le(ret).type(Res.type())\n",
    "\n",
    "    Res_1_AP = Res\n",
    "    Res_0_AP = 1-Res\n",
    "\n",
    "    Res_1[Res_1 != Res_1] = 0\n",
    "    Res_0[Res_0 != Res_0] = 0\n",
    "    Res_1_AP[Res_1_AP != Res_1_AP] = 0\n",
    "    Res_0_AP[Res_0_AP != Res_0_AP] = 0\n",
    "\n",
    "\n",
    "    # TEST\n",
    "    pred = Res.clamp(min=thr) / Res.max()\n",
    "    pred = pred.view(-1).data.cpu().numpy()\n",
    "    target = labels.view(-1).data.cpu().numpy()\n",
    "    # print(\"target\", target.shape)\n",
    "\n",
    "    output = torch.cat((Res_0, Res_1), 1)\n",
    "    output_AP = torch.cat((Res_0_AP, Res_1_AP), 1)\n",
    "\n",
    "\n",
    "    # Evaluate Segmentation\n",
    "    batch_inter, batch_union, batch_correct, batch_label = 0, 0, 0, 0\n",
    "    batch_ap, batch_f1 = 0, 0\n",
    "\n",
    "    # Segmentation resutls\n",
    "    # print(\"output\", output.shape)\n",
    "    # print(\"ap labels\", labels.shape)\n",
    "    correct, labeled = batch_pix_accuracy(output[0].data.cpu(), labels[0])\n",
    "    inter, union = batch_intersection_union(output[0].data.cpu(), labels[0], 2)\n",
    "    batch_correct += correct\n",
    "    batch_label += labeled\n",
    "    batch_inter += inter\n",
    "    batch_union += union\n",
    "    # print(\"output\", output.shape)\n",
    "    # print(\"ap labels\", labels.shape)\n",
    "    # ap = np.nan_to_num(get_ap_scores(output, labels))\n",
    "    ap = np.nan_to_num(get_ap_scores(output_AP, labels))\n",
    "    f1 = np.nan_to_num(get_f1_scores(output[0, 1].data.cpu(), labels[0]))\n",
    "    batch_ap += ap\n",
    "    batch_f1 += f1\n",
    "\n",
    "    return batch_correct, batch_label, batch_inter, batch_union, batch_ap, batch_f1, pred, target\n",
    "\n",
    "\n",
    "total_inter, total_union, total_correct, total_label = np.int64(0), np.int64(0), np.int64(0), np.int64(0)\n",
    "total_ap, total_f1 = [], []\n",
    "\n",
    "predictions, targets = [], []\n",
    "for batch_idx, (image, labels) in enumerate(iterator):\n",
    "\n",
    "    if method == \"blur\":\n",
    "        images = (image[0].cuda(), image[1].cuda())\n",
    "    else:\n",
    "        images = image.cuda()\n",
    "    labels = labels.cuda()\n",
    "    # print(\"image\", image.shape)\n",
    "    # print(\"lables\", labels.shape)\n",
    "\n",
    "    correct, labeled, inter, union, ap, f1, pred, target = eval_batch(images, labels, model, batch_idx)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    targets.append(target)\n",
    "\n",
    "    total_correct += correct.astype('int64')\n",
    "    total_label += labeled.astype('int64')\n",
    "    total_inter += inter.astype('int64')\n",
    "    total_union += union.astype('int64')\n",
    "    total_ap += [ap]\n",
    "    total_f1 += [f1]\n",
    "    pixAcc = np.float64(1.0) * total_correct / (np.spacing(1, dtype=np.float64) + total_label)\n",
    "    IoU = np.float64(1.0) * total_inter / (np.spacing(1, dtype=np.float64) + total_union)\n",
    "    mIoU = IoU.mean()\n",
    "    mAp = np.mean(total_ap)\n",
    "    mF1 = np.mean(total_f1)\n",
    "    iterator.set_description('pixAcc: %.4f, mIoU: %.4f, mAP: %.4f, mF1: %.4f' % (pixAcc, mIoU, mAp, mF1))\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "targets = np.concatenate(targets)\n",
    "pr, rc, thr = precision_recall_curve(targets, predictions)\n",
    "# np.save(os.path.join(saver.experiment_dir, 'precision.npy'), pr)\n",
    "# np.save(os.path.join(saver.experiment_dir, 'recall.npy'), rc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rc, pr)\n",
    "# plt.savefig(os.path.join(saver.experiment_dir, 'PR_curve_{}.png'.format(args.method)))\n",
    "\n",
    "# txtfile = os.path.join(saver.experiment_dir, 'result_mIoU_%.4f.txt' % mIoU)\n",
    "# txtfile = 'result_mIoU_%.4f.txt' % mIoU\n",
    "# fh = open(txtfile, 'w')\n",
    "print(\"Mean IoU over %d classes: %.4f\\n\" % (2, mIoU))\n",
    "print(\"Pixel-wise Accuracy: %2.2f%%\\n\" % (pixAcc * 100))\n",
    "print(\"Mean AP over %d classes: %.4f\\n\" % (2, mAp))\n",
    "print(\"Mean F1 over %d classes: %.4f\\n\" % (2, mF1))\n",
    "\n",
    "# fh.write(\"Mean IoU over %d classes: %.4f\\n\" % (2, mIoU))\n",
    "# fh.write(\"Pixel-wise Accuracy: %2.2f%%\\n\" % (pixAcc * 100))\n",
    "# fh.write(\"Mean AP over %d classes: %.4f\\n\" % (2, mAp))\n",
    "# fh.write(\"Mean F1 over %d classes: %.4f\\n\" % (2, mF1))\n",
    "# fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
