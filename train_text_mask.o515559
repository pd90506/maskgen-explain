LABEL_1
{'input_ids': tensor([[ 101, 1045,  103, 2023, 3185,  999,  102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}

I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say "Gene Roddenberry's Earth..." otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.
pred label LABEL_0
True label LABEL_0
params to be optimized: 
['similarity_measure.logit_scale', 'similarity_measure.pred_map.input_layer.weight', 'similarity_measure.pred_map.input_layer.bias', 'similarity_measure.pred_map.layers.0.0.weight', 'similarity_measure.pred_map.layers.0.0.bias', 'similarity_measure.pred_map.layers.0.3.weight', 'similarity_measure.pred_map.layers.0.3.bias', 'similarity_measure.pred_map.layers.0.6.weight', 'similarity_measure.pred_map.layers.0.6.bias', 'similarity_measure.pred_map.layers.1.0.weight', 'similarity_measure.pred_map.layers.1.0.bias', 'similarity_measure.pred_map.layers.1.3.weight', 'similarity_measure.pred_map.layers.1.3.bias', 'similarity_measure.pred_map.layers.1.6.weight', 'similarity_measure.pred_map.layers.1.6.bias', 'similarity_measure.pred_map.output_layer.weight', 'similarity_measure.pred_map.output_layer.bias', 'similarity_measure.explain_map.input_layer.weight', 'similarity_measure.explain_map.input_layer.bias', 'similarity_measure.explain_map.layers.0.0.weight', 'similarity_measure.explain_map.layers.0.0.bias', 'similarity_measure.explain_map.layers.0.3.weight', 'similarity_measure.explain_map.layers.0.3.bias', 'similarity_measure.explain_map.layers.0.6.weight', 'similarity_measure.explain_map.layers.0.6.bias', 'similarity_measure.explain_map.layers.1.0.weight', 'similarity_measure.explain_map.layers.1.0.bias', 'similarity_measure.explain_map.layers.1.3.weight', 'similarity_measure.explain_map.layers.1.3.bias', 'similarity_measure.explain_map.layers.1.6.weight', 'similarity_measure.explain_map.layers.1.6.bias', 'similarity_measure.explain_map.output_layer.weight', 'similarity_measure.explain_map.output_layer.bias']

  0%|          | 0/98 [00:00<?, ?it/s]Epoch 1, Step 1: Loss = 0.3857, Reward Loss = -0.0000, Mask Loss = 0.1929 mask_mean = 0.2332 prob_mean = 0.7742 :   0%|          | 0/98 [01:29<?, ?it/s]Epoch 1, Step 1: Loss = 0.3857, Reward Loss = -0.0000, Mask Loss = 0.1929 mask_mean = 0.2332 prob_mean = 0.7742 :   1%|          | 1/98 [01:36<2:35:25, 96.14s/it]Epoch 1, Step 2: Loss = 0.0833, Reward Loss = -0.2718, Mask Loss = 0.1776 mask_mean = 0.1922 prob_mean = 0.5101 :   1%|          | 1/98 [03:03<2:35:25, 96.14s/it]Epoch 1, Step 2: Loss = 0.0833, Reward Loss = -0.2718, Mask Loss = 0.1776 mask_mean = 0.1922 prob_mean = 0.5101 :   2%|▏         | 2/98 [03:03<2:25:29, 90.94s/it]Epoch 1, Step 3: Loss = -0.0191, Reward Loss = -0.3548, Mask Loss = 0.1679 mask_mean = 0.2176 prob_mean = 0.5011 :   2%|▏         | 2/98 [04:30<2:25:29, 90.94s/it]Epoch 1, Step 3: Loss = -0.0191, Reward Loss = -0.3548, Mask Loss = 0.1679 mask_mean = 0.2176 prob_mean = 0.5011 :   3%|▎         | 3/98 [04:30<2:21:06, 89.12s/it]Epoch 1, Step 4: Loss = -0.0850, Reward Loss = -0.4281, Mask Loss = 0.1715 mask_mean = 0.2167 prob_mean = 0.5359 :   3%|▎         | 3/98 [05:57<2:21:06, 89.12s/it]Epoch 1, Step 4: Loss = -0.0850, Reward Loss = -0.4281, Mask Loss = 0.1715 mask_mean = 0.2167 prob_mean = 0.5359 :   4%|▍         | 4/98 [05:57<2:18:18, 88.28s/it]Epoch 1, Step 5: Loss = -0.1430, Reward Loss = -0.4759, Mask Loss = 0.1664 mask_mean = 0.2246 prob_mean = 0.5601 :   4%|▍         | 4/98 [07:24<2:18:18, 88.28s/it]Epoch 1, Step 5: Loss = -0.1430, Reward Loss = -0.4759, Mask Loss = 0.1664 mask_mean = 0.2246 prob_mean = 0.5601 :   5%|▌         | 5/98 [07:24<2:16:02, 87.77s/it]Epoch 1, Step 6: Loss = -0.1470, Reward Loss = -0.4739, Mask Loss = 0.1635 mask_mean = 0.2236 prob_mean = 0.5469 :   5%|▌         | 5/98 [08:51<2:16:02, 87.77s/it]Epoch 1, Step 6: Loss = -0.1470, Reward Loss = -0.4739, Mask Loss = 0.1635 mask_mean = 0.2236 prob_mean = 0.5469 :   6%|▌         | 6/98 [08:51<2:14:04, 87.44s/it]Epoch 1, Step 7: Loss = -0.1900, Reward Loss = -0.5130, Mask Loss = 0.1615 mask_mean = 0.2183 prob_mean = 0.5673 :   6%|▌         | 6/98 [10:18<2:14:04, 87.44s/it]Epoch 1, Step 7: Loss = -0.1900, Reward Loss = -0.5130, Mask Loss = 0.1615 mask_mean = 0.2183 prob_mean = 0.5673 :   7%|▋         | 7/98 [10:18<2:12:23, 87.29s/it]Epoch 1, Step 8: Loss = -0.1693, Reward Loss = -0.4576, Mask Loss = 0.1441 mask_mean = 0.2250 prob_mean = 0.5382 :   7%|▋         | 7/98 [11:44<2:12:23, 87.29s/it]Epoch 1, Step 8: Loss = -0.1693, Reward Loss = -0.4576, Mask Loss = 0.1441 mask_mean = 0.2250 prob_mean = 0.5382 :   8%|▊         | 8/98 [11:44<2:10:45, 87.17s/it]Epoch 1, Step 9: Loss = -0.2009, Reward Loss = -0.4917, Mask Loss = 0.1454 mask_mean = 0.2288 prob_mean = 0.5597 :   8%|▊         | 8/98 [13:11<2:10:45, 87.17s/it]Epoch 1, Step 9: Loss = -0.2009, Reward Loss = -0.4917, Mask Loss = 0.1454 mask_mean = 0.2288 prob_mean = 0.5597 :   9%|▉         | 9/98 [13:11<2:09:11, 87.10s/it]Epoch 1, Step 10: Loss = -0.2508, Reward Loss = -0.5389, Mask Loss = 0.1440 mask_mean = 0.2255 prob_mean = 0.6023 :   9%|▉         | 9/98 [14:38<2:09:11, 87.10s/it]Epoch 1, Step 10: Loss = -0.2508, Reward Loss = -0.5389, Mask Loss = 0.1440 mask_mean = 0.2255 prob_mean = 0.6023 :  10%|█         | 10/98 [14:38<2:07:38, 87.03s/it]Epoch 1, Step 11: Loss = -0.2291, Reward Loss = -0.5108, Mask Loss = 0.1409 mask_mean = 0.2358 prob_mean = 0.5891 :  10%|█         | 10/98 [16:05<2:07:38, 87.03s/it]Epoch 1, Step 11: Loss = -0.2291, Reward Loss = -0.5108, Mask Loss = 0.1409 mask_mean = 0.2358 prob_mean = 0.5891 :  11%|█         | 11/98 [16:12<2:09:05, 89.03s/it]Epoch 1, Step 12: Loss = -0.2188, Reward Loss = -0.4939, Mask Loss = 0.1376 mask_mean = 0.2406 prob_mean = 0.5591 :  11%|█         | 11/98 [17:39<2:09:05, 89.03s/it]Epoch 1, Step 12: Loss = -0.2188, Reward Loss = -0.4939, Mask Loss = 0.1376 mask_mean = 0.2406 prob_mean = 0.5591 :  12%|█▏        | 12/98 [17:39<2:06:40, 88.38s/it]Epoch 1, Step 13: Loss = -0.2592, Reward Loss = -0.5386, Mask Loss = 0.1397 mask_mean = 0.2386 prob_mean = 0.6056 :  12%|█▏        | 12/98 [19:06<2:06:40, 88.38s/it]Epoch 1, Step 13: Loss = -0.2592, Reward Loss = -0.5386, Mask Loss = 0.1397 mask_mean = 0.2386 prob_mean = 0.6056 :  13%|█▎        | 13/98 [19:06<2:04:38, 87.98s/it]Epoch 1, Step 14: Loss = -0.2482, Reward Loss = -0.5330, Mask Loss = 0.1424 mask_mean = 0.2401 prob_mean = 0.5996 :  13%|█▎        | 13/98 [20:33<2:04:38, 87.98s/it]Epoch 1, Step 14: Loss = -0.2482, Reward Loss = -0.5330, Mask Loss = 0.1424 mask_mean = 0.2401 prob_mean = 0.5996 :  14%|█▍        | 14/98 [20:33<2:02:46, 87.69s/it]Epoch 1, Step 15: Loss = -0.2709, Reward Loss = -0.5137, Mask Loss = 0.1214 mask_mean = 0.2465 prob_mean = 0.5624 :  14%|█▍        | 14/98 [22:00<2:02:46, 87.69s/it]Epoch 1, Step 15: Loss = -0.2709, Reward Loss = -0.5137, Mask Loss = 0.1214 mask_mean = 0.2465 prob_mean = 0.5624 :  15%|█▌        | 15/98 [22:00<2:01:00, 87.47s/it]Epoch 1, Step 16: Loss = -0.2833, Reward Loss = -0.5578, Mask Loss = 0.1372 mask_mean = 0.2378 prob_mean = 0.6022 :  15%|█▌        | 15/98 [23:27<2:01:00, 87.47s/it]Epoch 1, Step 16: Loss = -0.2833, Reward Loss = -0.5578, Mask Loss = 0.1372 mask_mean = 0.2378 prob_mean = 0.6022 :  16%|█▋        | 16/98 [23:27<1:59:19, 87.31s/it]Epoch 1, Step 17: Loss = -0.2963, Reward Loss = -0.5880, Mask Loss = 0.1458 mask_mean = 0.2330 prob_mean = 0.6301 :  16%|█▋        | 16/98 [24:54<1:59:19, 87.31s/it]Epoch 1, Step 17: Loss = -0.2963, Reward Loss = -0.5880, Mask Loss = 0.1458 mask_mean = 0.2330 prob_mean = 0.6301 :  17%|█▋        | 17/98 [24:54<1:57:42, 87.19s/it]Epoch 1, Step 18: Loss = -0.2871, Reward Loss = -0.5455, Mask Loss = 0.1292 mask_mean = 0.2421 prob_mean = 0.5995 :  17%|█▋        | 17/98 [26:21<1:57:42, 87.19s/it]Epoch 1, Step 18: Loss = -0.2871, Reward Loss = -0.5455, Mask Loss = 0.1292 mask_mean = 0.2421 prob_mean = 0.5995 :  18%|█▊        | 18/98 [26:21<1:56:07, 87.10s/it]Epoch 1, Step 19: Loss = -0.2763, Reward Loss = -0.5368, Mask Loss = 0.1302 mask_mean = 0.2379 prob_mean = 0.5938 :  18%|█▊        | 18/98 [27:47<1:56:07, 87.10s/it]Epoch 1, Step 19: Loss = -0.2763, Reward Loss = -0.5368, Mask Loss = 0.1302 mask_mean = 0.2379 prob_mean = 0.5938 :  19%|█▉        | 19/98 [27:47<1:54:35, 87.03s/it]Epoch 1, Step 20: Loss = -0.2726, Reward Loss = -0.5253, Mask Loss = 0.1264 mask_mean = 0.2450 prob_mean = 0.5963 :  19%|█▉        | 19/98 [29:14<1:54:35, 87.03s/it]Epoch 1, Step 20: Loss = -0.2726, Reward Loss = -0.5253, Mask Loss = 0.1264 mask_mean = 0.2450 prob_mean = 0.5963 :  20%|██        | 20/98 [29:14<1:53:07, 87.01s/it]Epoch 1, Step 21: Loss = -0.2668, Reward Loss = -0.5292, Mask Loss = 0.1312 mask_mean = 0.2534 prob_mean = 0.6059 :  20%|██        | 20/98 [30:41<1:53:07, 87.01s/it]Epoch 1, Step 21: Loss = -0.2668, Reward Loss = -0.5292, Mask Loss = 0.1312 mask_mean = 0.2534 prob_mean = 0.6059 :  21%|██▏       | 21/98 [32:12<2:26:35, 114.23s/it]Epoch 1, Step 22: Loss = -0.2506, Reward Loss = -0.5674, Mask Loss = 0.1584 mask_mean = 0.2467 prob_mean = 0.6676 :  21%|██▏       | 21/98 [33:39<2:26:35, 114.23s/it]Epoch 1, Step 22: Loss = -0.2506, Reward Loss = -0.5674, Mask Loss = 0.1584 mask_mean = 0.2467 prob_mean = 0.6676 :  22%|██▏       | 22/98 [33:39<2:14:26, 106.14s/it]Epoch 1, Step 23: Loss = -0.2351, Reward Loss = -0.5510, Mask Loss = 0.1580 mask_mean = 0.2504 prob_mean = 0.6724 :  22%|██▏       | 22/98 [35:07<2:14:26, 106.14s/it]Epoch 1, Step 23: Loss = -0.2351, Reward Loss = -0.5510, Mask Loss = 0.1580 mask_mean = 0.2504 prob_mean = 0.6724 :  23%|██▎       | 23/98 [35:07<2:05:36, 100.49s/it]Epoch 1, Step 24: Loss = -0.2539, Reward Loss = -0.5990, Mask Loss = 0.1725 mask_mean = 0.2524 prob_mean = 0.6908 :  23%|██▎       | 23/98 [36:33<2:05:36, 100.49s/it]Epoch 1, Step 24: Loss = -0.2539, Reward Loss = -0.5990, Mask Loss = 0.1725 mask_mean = 0.2524 prob_mean = 0.6908 :  24%|██▍       | 24/98 [36:33<1:58:53, 96.39s/it] Epoch 1, Step 25: Loss = -0.2721, Reward Loss = -0.6115, Mask Loss = 0.1697 mask_mean = 0.2480 prob_mean = 0.6932 :  24%|██▍       | 24/98 [38:00<1:58:53, 96.39s/it]Epoch 1, Step 25: Loss = -0.2721, Reward Loss = -0.6115, Mask Loss = 0.1697 mask_mean = 0.2480 prob_mean = 0.6932 :  26%|██▌       | 25/98 [38:00<1:53:47, 93.53s/it]Epoch 1, Step 26: Loss = -0.2800, Reward Loss = -0.6238, Mask Loss = 0.1719 mask_mean = 0.2501 prob_mean = 0.6980 :  26%|██▌       | 25/98 [39:27<1:53:47, 93.53s/it]Epoch 1, Step 26: Loss = -0.2800, Reward Loss = -0.6238, Mask Loss = 0.1719 mask_mean = 0.2501 prob_mean = 0.6980 :  27%|██▋       | 26/98 [39:27<1:49:51, 91.54s/it]Epoch 1, Step 27: Loss = -0.2810, Reward Loss = -0.6033, Mask Loss = 0.1612 mask_mean = 0.2563 prob_mean = 0.6664 :  27%|██▋       | 26/98 [40:54<1:49:51, 91.54s/it]Epoch 1, Step 27: Loss = -0.2810, Reward Loss = -0.6033, Mask Loss = 0.1612 mask_mean = 0.2563 prob_mean = 0.6664 :  28%|██▊       | 27/98 [40:54<1:46:39, 90.14s/it]Epoch 1, Step 28: Loss = -0.2781, Reward Loss = -0.6098, Mask Loss = 0.1658 mask_mean = 0.2505 prob_mean = 0.6886 :  28%|██▊       | 27/98 [42:21<1:46:39, 90.14s/it]Epoch 1, Step 28: Loss = -0.2781, Reward Loss = -0.6098, Mask Loss = 0.1658 mask_mean = 0.2505 prob_mean = 0.6886 :  29%|██▊       | 28/98 [42:21<1:44:01, 89.16s/it]Epoch 1, Step 29: Loss = -0.2876, Reward Loss = -0.5823, Mask Loss = 0.1473 mask_mean = 0.2498 prob_mean = 0.6475 :  29%|██▊       | 28/98 [43:48<1:44:01, 89.16s/it]Epoch 1, Step 29: Loss = -0.2876, Reward Loss = -0.5823, Mask Loss = 0.1473 mask_mean = 0.2498 prob_mean = 0.6475 :  30%|██▉       | 29/98 [43:48<1:41:46, 88.49s/it]Epoch 1, Step 30: Loss = -0.2842, Reward Loss = -0.5771, Mask Loss = 0.1464 mask_mean = 0.2512 prob_mean = 0.6397 :  30%|██▉       | 29/98 [45:15<1:41:46, 88.49s/it]Epoch 1, Step 30: Loss = -0.2842, Reward Loss = -0.5771, Mask Loss = 0.1464 mask_mean = 0.2512 prob_mean = 0.6397 :  31%|███       | 30/98 [45:15<1:39:44, 88.00s/it]Epoch 1, Step 31: Loss = -0.2952, Reward Loss = -0.5851, Mask Loss = 0.1450 mask_mean = 0.2441 prob_mean = 0.6445 :  31%|███       | 30/98 [46:42<1:39:44, 88.00s/it]Epoch 1, Step 31: Loss = -0.2952, Reward Loss = -0.5851, Mask Loss = 0.1450 mask_mean = 0.2441 prob_mean = 0.6445 :  32%|███▏      | 31/98 [46:47<1:39:39, 89.25s/it]Epoch 1, Step 32: Loss = -0.3208, Reward Loss = -0.6386, Mask Loss = 0.1589 mask_mean = 0.2295 prob_mean = 0.6961 :  32%|███▏      | 31/98 [48:14<1:39:39, 89.25s/it]Epoch 1, Step 32: Loss = -0.3208, Reward Loss = -0.6386, Mask Loss = 0.1589 mask_mean = 0.2295 prob_mean = 0.6961 :  33%|███▎      | 32/98 [48:14<1:37:24, 88.55s/it]Epoch 1, Step 33: Loss = -0.2970, Reward Loss = -0.5597, Mask Loss = 0.1314 mask_mean = 0.2444 prob_mean = 0.6289 :  33%|███▎      | 32/98 [49:41<1:37:24, 88.55s/it]Epoch 1, Step 33: Loss = -0.2970, Reward Loss = -0.5597, Mask Loss = 0.1314 mask_mean = 0.2444 prob_mean = 0.6289 :  34%|███▎      | 33/98 [49:41<1:35:23, 88.06s/it]Epoch 1, Step 34: Loss = -0.3043, Reward Loss = -0.5816, Mask Loss = 0.1387 mask_mean = 0.2357 prob_mean = 0.6357 :  34%|███▎      | 33/98 [51:08<1:35:23, 88.06s/it]Epoch 1, Step 34: Loss = -0.3043, Reward Loss = -0.5816, Mask Loss = 0.1387 mask_mean = 0.2357 prob_mean = 0.6357 :  35%|███▍      | 34/98 [51:08<1:33:33, 87.72s/it]Epoch 1, Step 35: Loss = -0.3065, Reward Loss = -0.5479, Mask Loss = 0.1207 mask_mean = 0.2427 prob_mean = 0.6139 :  35%|███▍      | 34/98 [52:35<1:33:33, 87.72s/it]Epoch 1, Step 35: Loss = -0.3065, Reward Loss = -0.5479, Mask Loss = 0.1207 mask_mean = 0.2427 prob_mean = 0.6139 :  36%|███▌      | 35/98 [52:35<1:31:51, 87.49s/it]Epoch 1, Step 36: Loss = -0.3223, Reward Loss = -0.5964, Mask Loss = 0.1371 mask_mean = 0.2290 prob_mean = 0.6579 :  36%|███▌      | 35/98 [54:02<1:31:51, 87.49s/it]Epoch 1, Step 36: Loss = -0.3223, Reward Loss = -0.5964, Mask Loss = 0.1371 mask_mean = 0.2290 prob_mean = 0.6579 :  37%|███▋      | 36/98 [54:02<1:30:13, 87.31s/it]Epoch 1, Step 37: Loss = -0.3345, Reward Loss = -0.6207, Mask Loss = 0.1431 mask_mean = 0.2200 prob_mean = 0.6852 :  37%|███▋      | 36/98 [55:28<1:30:13, 87.31s/it]Epoch 1, Step 37: Loss = -0.3345, Reward Loss = -0.6207, Mask Loss = 0.1431 mask_mean = 0.2200 prob_mean = 0.6852 :  38%|███▊      | 37/98 [55:28<1:28:37, 87.17s/it]Epoch 1, Step 38: Loss = -0.2991, Reward Loss = -0.5892, Mask Loss = 0.1451 mask_mean = 0.2242 prob_mean = 0.6701 :  38%|███▊      | 37/98 [56:55<1:28:37, 87.17s/it]Epoch 1, Step 38: Loss = -0.2991, Reward Loss = -0.5892, Mask Loss = 0.1451 mask_mean = 0.2242 prob_mean = 0.6701 :  39%|███▉      | 38/98 [56:55<1:27:09, 87.15s/it]Epoch 1, Step 39: Loss = -0.3006, Reward Loss = -0.5640, Mask Loss = 0.1317 mask_mean = 0.2299 prob_mean = 0.6421 :  39%|███▉      | 38/98 [58:29<1:27:09, 87.15s/it]Epoch 1, Step 39: Loss = -0.3006, Reward Loss = -0.5640, Mask Loss = 0.1317 mask_mean = 0.2299 prob_mean = 0.6421 :  40%|███▉      | 39/98 [58:29<1:27:34, 89.06s/it]Epoch 1, Step 40: Loss = -0.3174, Reward Loss = -0.5876, Mask Loss = 0.1351 mask_mean = 0.2265 prob_mean = 0.6625 :  40%|███▉      | 39/98 [59:56<1:27:34, 89.06s/it]Epoch 1, Step 40: Loss = -0.3174, Reward Loss = -0.5876, Mask Loss = 0.1351 mask_mean = 0.2265 prob_mean = 0.6625 :  41%|████      | 40/98 [59:56<1:25:26, 88.38s/it]Epoch 1, Step 41: Loss = -0.3248, Reward Loss = -0.6163, Mask Loss = 0.1457 mask_mean = 0.2175 prob_mean = 0.6933 :  41%|████      | 40/98 [1:01:23<1:25:26, 88.38s/it]Epoch 1, Step 41: Loss = -0.3248, Reward Loss = -0.6163, Mask Loss = 0.1457 mask_mean = 0.2175 prob_mean = 0.6933 :  42%|████▏     | 41/98 [1:01:28<1:24:55, 89.39s/it]Epoch 1, Step 42: Loss = -0.3063, Reward Loss = -0.5921, Mask Loss = 0.1429 mask_mean = 0.2200 prob_mean = 0.6750 :  42%|████▏     | 41/98 [1:02:54<1:24:55, 89.39s/it]Epoch 1, Step 42: Loss = -0.3063, Reward Loss = -0.5921, Mask Loss = 0.1429 mask_mean = 0.2200 prob_mean = 0.6750 :  43%|████▎     | 42/98 [1:02:54<1:22:43, 88.63s/it]Epoch 1, Step 43: Loss = -0.3167, Reward Loss = -0.6000, Mask Loss = 0.1417 mask_mean = 0.2186 prob_mean = 0.6844 :  43%|████▎     | 42/98 [1:04:03<1:22:43, 88.63s/it]Epoch 1, Step 43: Loss = -0.3167, Reward Loss = -0.6000, Mask Loss = 0.1417 mask_mean = 0.2186 prob_mean = 0.6844 :  44%|████▍     | 43/98 [1:04:03<1:15:43, 82.61s/it]Epoch 1, Step 44: Loss = -0.3105, Reward Loss = -0.6136, Mask Loss = 0.1515 mask_mean = 0.2180 prob_mean = 0.7068 :  44%|████▍     | 43/98 [1:05:11<1:15:43, 82.61s/it]Epoch 1, Step 44: Loss = -0.3105, Reward Loss = -0.6136, Mask Loss = 0.1515 mask_mean = 0.2180 prob_mean = 0.7068 :  45%|████▍     | 44/98 [1:05:11<1:10:30, 78.35s/it]Epoch 1, Step 45: Loss = -0.2952, Reward Loss = -0.6053, Mask Loss = 0.1550 mask_mean = 0.2162 prob_mean = 0.7003 :  45%|████▍     | 44/98 [1:06:20<1:10:30, 78.35s/it]Epoch 1, Step 45: Loss = -0.2952, Reward Loss = -0.6053, Mask Loss = 0.1550 mask_mean = 0.2162 prob_mean = 0.7003 :  46%|████▌     | 45/98 [1:06:20<1:06:36, 75.40s/it]Epoch 1, Step 46: Loss = -0.3000, Reward Loss = -0.5709, Mask Loss = 0.1355 mask_mean = 0.2238 prob_mean = 0.6640 :  46%|████▌     | 45/98 [1:07:28<1:06:36, 75.40s/it]Epoch 1, Step 46: Loss = -0.3000, Reward Loss = -0.5709, Mask Loss = 0.1355 mask_mean = 0.2238 prob_mean = 0.6640 :  47%|████▋     | 46/98 [1:07:28<1:03:33, 73.33s/it]Epoch 1, Step 47: Loss = -0.3006, Reward Loss = -0.6093, Mask Loss = 0.1544 mask_mean = 0.2152 prob_mean = 0.7131 :  47%|████▋     | 46/98 [1:08:37<1:03:33, 73.33s/it]Epoch 1, Step 47: Loss = -0.3006, Reward Loss = -0.6093, Mask Loss = 0.1544 mask_mean = 0.2152 prob_mean = 0.7131 :  48%|████▊     | 47/98 [1:08:37<1:01:06, 71.89s/it]Epoch 1, Step 48: Loss = -0.3060, Reward Loss = -0.5797, Mask Loss = 0.1369 mask_mean = 0.2179 prob_mean = 0.6719 :  48%|████▊     | 47/98 [1:09:46<1:01:06, 71.89s/it]Epoch 1, Step 48: Loss = -0.3060, Reward Loss = -0.5797, Mask Loss = 0.1369 mask_mean = 0.2179 prob_mean = 0.6719 :  49%|████▉     | 48/98 [1:09:46<59:06, 70.93s/it]  Epoch 1, Step 49: Loss = -0.3048, Reward Loss = -0.5867, Mask Loss = 0.1409 mask_mean = 0.2138 prob_mean = 0.6793 :  49%|████▉     | 48/98 [1:10:54<59:06, 70.93s/it]Epoch 1, Step 49: Loss = -0.3048, Reward Loss = -0.5867, Mask Loss = 0.1409 mask_mean = 0.2138 prob_mean = 0.6793 :  50%|█████     | 49/98 [1:10:54<57:19, 70.20s/it]Epoch 1, Step 50: Loss = -0.2928, Reward Loss = -0.5671, Mask Loss = 0.1371 mask_mean = 0.2167 prob_mean = 0.6698 :  50%|█████     | 49/98 [1:12:02<57:19, 70.20s/it]Epoch 1, Step 50: Loss = -0.2928, Reward Loss = -0.5671, Mask Loss = 0.1371 mask_mean = 0.2167 prob_mean = 0.6698 :  51%|█████     | 50/98 [1:12:02<55:44, 69.67s/it]Epoch 1, Step 51: Loss = -0.2897, Reward Loss = -0.5761, Mask Loss = 0.1432 mask_mean = 0.2141 prob_mean = 0.6919 :  51%|█████     | 50/98 [1:13:11<55:44, 69.67s/it]Epoch 1, Step 51: Loss = -0.2897, Reward Loss = -0.5761, Mask Loss = 0.1432 mask_mean = 0.2141 prob_mean = 0.6919 :  52%|█████▏    | 51/98 [1:13:15<55:14, 70.52s/it]Epoch 1, Step 52: Loss = -0.2768, Reward Loss = -0.5965, Mask Loss = 0.1598 mask_mean = 0.2124 prob_mean = 0.7138 :  52%|█████▏    | 51/98 [1:14:24<55:14, 70.52s/it]Epoch 1, Step 52: Loss = -0.2768, Reward Loss = -0.5965, Mask Loss = 0.1598 mask_mean = 0.2124 prob_mean = 0.7138 :  53%|█████▎    | 52/98 [1:14:24<53:40, 70.00s/it]Epoch 1, Step 53: Loss = -0.2796, Reward Loss = -0.5829, Mask Loss = 0.1517 mask_mean = 0.2113 prob_mean = 0.7108 :  53%|█████▎    | 52/98 [1:15:32<53:40, 70.00s/it]Epoch 1, Step 53: Loss = -0.2796, Reward Loss = -0.5829, Mask Loss = 0.1517 mask_mean = 0.2113 prob_mean = 0.7108 :  54%|█████▍    | 53/98 [1:15:32<52:09, 69.54s/it]Epoch 1, Step 54: Loss = -0.2836, Reward Loss = -0.6034, Mask Loss = 0.1599 mask_mean = 0.2069 prob_mean = 0.7300 :  54%|█████▍    | 53/98 [1:16:41<52:09, 69.54s/it]Epoch 1, Step 54: Loss = -0.2836, Reward Loss = -0.6034, Mask Loss = 0.1599 mask_mean = 0.2069 prob_mean = 0.7300 :  55%|█████▌    | 54/98 [1:16:41<50:46, 69.24s/it]Epoch 1, Step 55: Loss = -0.2473, Reward Loss = -0.5984, Mask Loss = 0.1755 mask_mean = 0.2133 prob_mean = 0.7482 :  55%|█████▌    | 54/98 [1:17:49<50:46, 69.24s/it]Epoch 1, Step 55: Loss = -0.2473, Reward Loss = -0.5984, Mask Loss = 0.1755 mask_mean = 0.2133 prob_mean = 0.7482 :  56%|█████▌    | 55/98 [1:17:49<49:27, 69.01s/it]Epoch 1, Step 56: Loss = -0.2302, Reward Loss = -0.6064, Mask Loss = 0.1881 mask_mean = 0.2097 prob_mean = 0.7738 :  56%|█████▌    | 55/98 [1:18:58<49:27, 69.01s/it]Epoch 1, Step 56: Loss = -0.2302, Reward Loss = -0.6064, Mask Loss = 0.1881 mask_mean = 0.2097 prob_mean = 0.7738 :  57%|█████▋    | 56/98 [1:18:58<48:11, 68.84s/it]Epoch 1, Step 57: Loss = -0.2191, Reward Loss = -0.5732, Mask Loss = 0.1771 mask_mean = 0.2208 prob_mean = 0.7546 :  57%|█████▋    | 56/98 [1:20:06<48:11, 68.84s/it]Epoch 1, Step 57: Loss = -0.2191, Reward Loss = -0.5732, Mask Loss = 0.1771 mask_mean = 0.2208 prob_mean = 0.7546 :  58%|█████▊    | 57/98 [1:20:06<46:58, 68.74s/it]Epoch 1, Step 58: Loss = -0.1740, Reward Loss = -0.5623, Mask Loss = 0.1941 mask_mean = 0.2307 prob_mean = 0.7532 :  58%|█████▊    | 57/98 [1:21:15<46:58, 68.74s/it]Epoch 1, Step 58: Loss = -0.1740, Reward Loss = -0.5623, Mask Loss = 0.1941 mask_mean = 0.2307 prob_mean = 0.7532 :  59%|█████▉    | 58/98 [1:21:15<45:46, 68.67s/it]Epoch 1, Step 59: Loss = -0.1909, Reward Loss = -0.5933, Mask Loss = 0.2012 mask_mean = 0.2212 prob_mean = 0.7777 :  59%|█████▉    | 58/98 [1:22:23<45:46, 68.67s/it]Epoch 1, Step 59: Loss = -0.1909, Reward Loss = -0.5933, Mask Loss = 0.2012 mask_mean = 0.2212 prob_mean = 0.7777 :  60%|██████    | 59/98 [1:22:23<44:36, 68.63s/it]Epoch 1, Step 60: Loss = -0.1722, Reward Loss = -0.5806, Mask Loss = 0.2042 mask_mean = 0.2277 prob_mean = 0.7682 :  60%|██████    | 59/98 [1:23:32<44:36, 68.63s/it]Epoch 1, Step 60: Loss = -0.1722, Reward Loss = -0.5806, Mask Loss = 0.2042 mask_mean = 0.2277 prob_mean = 0.7682 :  61%|██████    | 60/98 [1:23:32<43:26, 68.59s/it]Epoch 1, Step 61: Loss = -0.1695, Reward Loss = -0.5518, Mask Loss = 0.1911 mask_mean = 0.2315 prob_mean = 0.7464 :  61%|██████    | 60/98 [1:24:40<43:26, 68.59s/it]Epoch 1, Step 61: Loss = -0.1695, Reward Loss = -0.5518, Mask Loss = 0.1911 mask_mean = 0.2315 prob_mean = 0.7464 :  62%|██████▏   | 61/98 [1:24:41<42:30, 68.92s/it]Epoch 1, Step 62: Loss = -0.2292, Reward Loss = -0.5746, Mask Loss = 0.1727 mask_mean = 0.2235 prob_mean = 0.7305 :  62%|██████▏   | 61/98 [1:25:50<42:30, 68.92s/it]Epoch 1, Step 62: Loss = -0.2292, Reward Loss = -0.5746, Mask Loss = 0.1727 mask_mean = 0.2235 prob_mean = 0.7305 :  63%|██████▎   | 62/98 [1:25:50<41:16, 68.80s/it]Epoch 1, Step 63: Loss = -0.2475, Reward Loss = -0.6010, Mask Loss = 0.1768 mask_mean = 0.2173 prob_mean = 0.7569 :  63%|██████▎   | 62/98 [1:26:58<41:16, 68.80s/it]Epoch 1, Step 63: Loss = -0.2475, Reward Loss = -0.6010, Mask Loss = 0.1768 mask_mean = 0.2173 prob_mean = 0.7569 :  64%|██████▍   | 63/98 [1:26:58<40:04, 68.70s/it]Epoch 1, Step 64: Loss = -0.2371, Reward Loss = -0.5687, Mask Loss = 0.1658 mask_mean = 0.2183 prob_mean = 0.7183 :  64%|██████▍   | 63/98 [1:28:07<40:04, 68.70s/it]Epoch 1, Step 64: Loss = -0.2371, Reward Loss = -0.5687, Mask Loss = 0.1658 mask_mean = 0.2183 prob_mean = 0.7183 :  65%|██████▌   | 64/98 [1:28:07<38:54, 68.65s/it]Epoch 1, Step 65: Loss = -0.2512, Reward Loss = -0.6009, Mask Loss = 0.1749 mask_mean = 0.2111 prob_mean = 0.7567 :  65%|██████▌   | 64/98 [1:29:15<38:54, 68.65s/it]Epoch 1, Step 65: Loss = -0.2512, Reward Loss = -0.6009, Mask Loss = 0.1749 mask_mean = 0.2111 prob_mean = 0.7567 :  66%|██████▋   | 65/98 [1:29:15<37:43, 68.60s/it]Epoch 1, Step 66: Loss = -0.2047, Reward Loss = -0.5664, Mask Loss = 0.1808 mask_mean = 0.2189 prob_mean = 0.7462 :  66%|██████▋   | 65/98 [1:30:24<37:43, 68.60s/it]Epoch 1, Step 66: Loss = -0.2047, Reward Loss = -0.5664, Mask Loss = 0.1808 mask_mean = 0.2189 prob_mean = 0.7462 :  67%|██████▋   | 66/98 [1:30:24<36:34, 68.57s/it]Epoch 1, Step 67: Loss = -0.2165, Reward Loss = -0.5879, Mask Loss = 0.1857 mask_mean = 0.2193 prob_mean = 0.7612 :  67%|██████▋   | 66/98 [1:31:32<36:34, 68.57s/it]Epoch 1, Step 67: Loss = -0.2165, Reward Loss = -0.5879, Mask Loss = 0.1857 mask_mean = 0.2193 prob_mean = 0.7612 :  68%|██████▊   | 67/98 [1:31:32<35:24, 68.54s/it]Epoch 1, Step 68: Loss = -0.2516, Reward Loss = -0.5805, Mask Loss = 0.1644 mask_mean = 0.2122 prob_mean = 0.7297 :  68%|██████▊   | 67/98 [1:32:41<35:24, 68.54s/it]Epoch 1, Step 68: Loss = -0.2516, Reward Loss = -0.5805, Mask Loss = 0.1644 mask_mean = 0.2122 prob_mean = 0.7297 :  69%|██████▉   | 68/98 [1:32:41<34:16, 68.54s/it]Epoch 1, Step 69: Loss = -0.2467, Reward Loss = -0.5713, Mask Loss = 0.1623 mask_mean = 0.2148 prob_mean = 0.7236 :  69%|██████▉   | 68/98 [1:33:49<34:16, 68.54s/it]Epoch 1, Step 69: Loss = -0.2467, Reward Loss = -0.5713, Mask Loss = 0.1623 mask_mean = 0.2148 prob_mean = 0.7236 :  70%|███████   | 69/98 [1:33:49<33:07, 68.53s/it]Epoch 1, Step 70: Loss = -0.2491, Reward Loss = -0.6019, Mask Loss = 0.1764 mask_mean = 0.2065 prob_mean = 0.7590 :  70%|███████   | 69/98 [1:34:58<33:07, 68.53s/it]Epoch 1, Step 70: Loss = -0.2491, Reward Loss = -0.6019, Mask Loss = 0.1764 mask_mean = 0.2065 prob_mean = 0.7590 :  71%|███████▏  | 70/98 [1:34:58<31:58, 68.53s/it]Epoch 1, Step 71: Loss = -0.2538, Reward Loss = -0.5673, Mask Loss = 0.1568 mask_mean = 0.2089 prob_mean = 0.7189 :  71%|███████▏  | 70/98 [1:36:07<31:58, 68.53s/it]Epoch 1, Step 71: Loss = -0.2538, Reward Loss = -0.5673, Mask Loss = 0.1568 mask_mean = 0.2089 prob_mean = 0.7189 :  72%|███████▏  | 71/98 [1:36:12<31:31, 70.04s/it]Epoch 1, Step 72: Loss = -0.2413, Reward Loss = -0.5434, Mask Loss = 0.1510 mask_mean = 0.2108 prob_mean = 0.6970 :  72%|███████▏  | 71/98 [1:37:20<31:31, 70.04s/it]Epoch 1, Step 72: Loss = -0.2413, Reward Loss = -0.5434, Mask Loss = 0.1510 mask_mean = 0.2108 prob_mean = 0.6970 :  73%|███████▎  | 72/98 [1:37:20<30:08, 69.56s/it]Epoch 1, Step 73: Loss = -0.2586, Reward Loss = -0.5553, Mask Loss = 0.1484 mask_mean = 0.2075 prob_mean = 0.7049 :  73%|███████▎  | 72/98 [1:38:29<30:08, 69.56s/it]Epoch 1, Step 73: Loss = -0.2586, Reward Loss = -0.5553, Mask Loss = 0.1484 mask_mean = 0.2075 prob_mean = 0.7049 :  74%|███████▍  | 73/98 [1:38:29<28:51, 69.24s/it]Epoch 1, Step 74: Loss = -0.2730, Reward Loss = -0.5731, Mask Loss = 0.1500 mask_mean = 0.2007 prob_mean = 0.7267 :  74%|███████▍  | 73/98 [1:39:37<28:51, 69.24s/it]Epoch 1, Step 74: Loss = -0.2730, Reward Loss = -0.5731, Mask Loss = 0.1500 mask_mean = 0.2007 prob_mean = 0.7267 :  76%|███████▌  | 74/98 [1:39:37<27:36, 69.02s/it]Epoch 1, Step 75: Loss = -0.2834, Reward Loss = -0.5734, Mask Loss = 0.1450 mask_mean = 0.1980 prob_mean = 0.7207 :  76%|███████▌  | 74/98 [1:40:45<27:36, 69.02s/it]Epoch 1, Step 75: Loss = -0.2834, Reward Loss = -0.5734, Mask Loss = 0.1450 mask_mean = 0.1980 prob_mean = 0.7207 :  77%|███████▋  | 75/98 [1:40:45<26:23, 68.86s/it]Epoch 1, Step 76: Loss = -0.2933, Reward Loss = -0.5751, Mask Loss = 0.1409 mask_mean = 0.2000 prob_mean = 0.7043 :  77%|███████▋  | 75/98 [1:41:54<26:23, 68.86s/it]Epoch 1, Step 76: Loss = -0.2933, Reward Loss = -0.5751, Mask Loss = 0.1409 mask_mean = 0.2000 prob_mean = 0.7043 :  78%|███████▊  | 76/98 [1:41:54<25:12, 68.76s/it]Epoch 1, Step 77: Loss = -0.2955, Reward Loss = -0.6047, Mask Loss = 0.1546 mask_mean = 0.1918 prob_mean = 0.7378 :  78%|███████▊  | 76/98 [1:43:03<25:12, 68.76s/it]Epoch 1, Step 77: Loss = -0.2955, Reward Loss = -0.6047, Mask Loss = 0.1546 mask_mean = 0.1918 prob_mean = 0.7378 :  79%|███████▊  | 77/98 [1:43:03<24:02, 68.68s/it]Epoch 1, Step 78: Loss = -0.2455, Reward Loss = -0.5180, Mask Loss = 0.1362 mask_mean = 0.2080 prob_mean = 0.6715 :  79%|███████▊  | 77/98 [1:44:11<24:02, 68.68s/it]Epoch 1, Step 78: Loss = -0.2455, Reward Loss = -0.5180, Mask Loss = 0.1362 mask_mean = 0.2080 prob_mean = 0.6715 :  80%|███████▉  | 78/98 [1:44:11<22:52, 68.63s/it]Epoch 1, Step 79: Loss = -0.2744, Reward Loss = -0.5653, Mask Loss = 0.1454 mask_mean = 0.1975 prob_mean = 0.7082 :  80%|███████▉  | 78/98 [1:45:20<22:52, 68.63s/it]Epoch 1, Step 79: Loss = -0.2744, Reward Loss = -0.5653, Mask Loss = 0.1454 mask_mean = 0.1975 prob_mean = 0.7082 :  81%|████████  | 79/98 [1:45:20<21:43, 68.60s/it]Epoch 1, Step 80: Loss = -0.2920, Reward Loss = -0.5568, Mask Loss = 0.1324 mask_mean = 0.1975 prob_mean = 0.6922 :  81%|████████  | 79/98 [1:46:28<21:43, 68.60s/it]Epoch 1, Step 80: Loss = -0.2920, Reward Loss = -0.5568, Mask Loss = 0.1324 mask_mean = 0.1975 prob_mean = 0.6922 :  82%|████████▏ | 80/98 [1:46:28<20:34, 68.59s/it]Epoch 1, Step 81: Loss = -0.2409, Reward Loss = -0.5409, Mask Loss = 0.1500 mask_mean = 0.1994 prob_mean = 0.7125 :  82%|████████▏ | 80/98 [1:47:37<20:34, 68.59s/it]Epoch 1, Step 81: Loss = -0.2409, Reward Loss = -0.5409, Mask Loss = 0.1500 mask_mean = 0.1994 prob_mean = 0.7125 :  83%|████████▎ | 81/98 [1:47:47<20:17, 71.64s/it]Epoch 1, Step 82: Loss = -0.2393, Reward Loss = -0.5479, Mask Loss = 0.1543 mask_mean = 0.1985 prob_mean = 0.7285 :  83%|████████▎ | 81/98 [1:48:55<20:17, 71.64s/it]Epoch 1, Step 82: Loss = -0.2393, Reward Loss = -0.5479, Mask Loss = 0.1543 mask_mean = 0.1985 prob_mean = 0.7285 :  84%|████████▎ | 82/98 [1:48:55<18:50, 70.67s/it]Epoch 1, Step 83: Loss = -0.2415, Reward Loss = -0.5557, Mask Loss = 0.1571 mask_mean = 0.1976 prob_mean = 0.7410 :  84%|████████▎ | 82/98 [1:50:04<18:50, 70.67s/it]Epoch 1, Step 83: Loss = -0.2415, Reward Loss = -0.5557, Mask Loss = 0.1571 mask_mean = 0.1976 prob_mean = 0.7410 :  85%|████████▍ | 83/98 [1:50:04<17:30, 70.03s/it]Epoch 1, Step 84: Loss = -0.2342, Reward Loss = -0.5554, Mask Loss = 0.1606 mask_mean = 0.1994 prob_mean = 0.7392 :  85%|████████▍ | 83/98 [1:51:12<17:30, 70.03s/it]Epoch 1, Step 84: Loss = -0.2342, Reward Loss = -0.5554, Mask Loss = 0.1606 mask_mean = 0.1994 prob_mean = 0.7392 :  86%|████████▌ | 84/98 [1:51:12<16:13, 69.57s/it]Epoch 1, Step 85: Loss = -0.2484, Reward Loss = -0.5648, Mask Loss = 0.1582 mask_mean = 0.1960 prob_mean = 0.7380 :  86%|████████▌ | 84/98 [1:52:21<16:13, 69.57s/it]Epoch 1, Step 85: Loss = -0.2484, Reward Loss = -0.5648, Mask Loss = 0.1582 mask_mean = 0.1960 prob_mean = 0.7380 :  87%|████████▋ | 85/98 [1:52:21<15:00, 69.26s/it]Epoch 1, Step 86: Loss = -0.1972, Reward Loss = -0.5138, Mask Loss = 0.1583 mask_mean = 0.2087 prob_mean = 0.7114 :  87%|████████▋ | 85/98 [1:53:29<15:00, 69.26s/it]Epoch 1, Step 86: Loss = -0.1972, Reward Loss = -0.5138, Mask Loss = 0.1583 mask_mean = 0.2087 prob_mean = 0.7114 :  88%|████████▊ | 86/98 [1:53:29<13:48, 69.03s/it]Epoch 1, Step 87: Loss = -0.2302, Reward Loss = -0.5516, Mask Loss = 0.1607 mask_mean = 0.1976 prob_mean = 0.7445 :  88%|████████▊ | 86/98 [1:54:38<13:48, 69.03s/it]Epoch 1, Step 87: Loss = -0.2302, Reward Loss = -0.5516, Mask Loss = 0.1607 mask_mean = 0.1976 prob_mean = 0.7445 :  89%|████████▉ | 87/98 [1:54:38<12:37, 68.87s/it]Epoch 1, Step 88: Loss = -0.2423, Reward Loss = -0.5685, Mask Loss = 0.1631 mask_mean = 0.1887 prob_mean = 0.7515 :  89%|████████▉ | 87/98 [1:55:46<12:37, 68.87s/it]Epoch 1, Step 88: Loss = -0.2423, Reward Loss = -0.5685, Mask Loss = 0.1631 mask_mean = 0.1887 prob_mean = 0.7515 :  90%|████████▉ | 88/98 [1:55:46<11:27, 68.77s/it]Epoch 1, Step 89: Loss = -0.2152, Reward Loss = -0.5350, Mask Loss = 0.1599 mask_mean = 0.1969 prob_mean = 0.7424 :  90%|████████▉ | 88/98 [1:56:55<11:27, 68.77s/it]Epoch 1, Step 89: Loss = -0.2152, Reward Loss = -0.5350, Mask Loss = 0.1599 mask_mean = 0.1969 prob_mean = 0.7424 :  91%|█████████ | 89/98 [1:56:55<10:18, 68.68s/it]Epoch 1, Step 90: Loss = -0.2105, Reward Loss = -0.5121, Mask Loss = 0.1508 mask_mean = 0.1989 prob_mean = 0.7205 :  91%|█████████ | 89/98 [1:58:03<10:18, 68.68s/it]Epoch 1, Step 90: Loss = -0.2105, Reward Loss = -0.5121, Mask Loss = 0.1508 mask_mean = 0.1989 prob_mean = 0.7205 :  92%|█████████▏| 90/98 [1:58:03<09:08, 68.62s/it]Epoch 1, Step 91: Loss = -0.2064, Reward Loss = -0.4909, Mask Loss = 0.1423 mask_mean = 0.2011 prob_mean = 0.6946 :  92%|█████████▏| 90/98 [1:59:12<09:08, 68.62s/it]Epoch 1, Step 91: Loss = -0.2064, Reward Loss = -0.4909, Mask Loss = 0.1423 mask_mean = 0.2011 prob_mean = 0.6946 :  93%|█████████▎| 91/98 [1:59:17<08:09, 69.99s/it]Epoch 1, Step 92: Loss = -0.2444, Reward Loss = -0.5296, Mask Loss = 0.1426 mask_mean = 0.1971 prob_mean = 0.7123 :  93%|█████████▎| 91/98 [2:00:25<08:09, 69.99s/it]Epoch 1, Step 92: Loss = -0.2444, Reward Loss = -0.5296, Mask Loss = 0.1426 mask_mean = 0.1971 prob_mean = 0.7123 :  94%|█████████▍| 92/98 [2:00:25<06:57, 69.51s/it]Epoch 1, Step 93: Loss = -0.2621, Reward Loss = -0.5560, Mask Loss = 0.1469 mask_mean = 0.1879 prob_mean = 0.7160 :  94%|█████████▍| 92/98 [2:01:33<06:57, 69.51s/it]Epoch 1, Step 93: Loss = -0.2621, Reward Loss = -0.5560, Mask Loss = 0.1469 mask_mean = 0.1879 prob_mean = 0.7160 :  95%|█████████▍| 93/98 [2:01:33<05:46, 69.22s/it]