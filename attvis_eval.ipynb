{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/crc/c/conda/23.5.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, ViTModel, ViTConfig, TrainingArguments, Trainer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from datasets import load_dataset,load_metric\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "import sys\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Siamese cat, Siamese\n"
     ]
    }
   ],
   "source": [
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# url = \"http://farm3.staticflickr.com/2066/1798910782_5536af8767_z.jpg\"\n",
    "url = \"http://farm1.staticflickr.com/184/399924547_98e6cef97a_z.jpg\"\n",
    "# url = \"http://farm1.staticflickr.com/128/318959350_1a39aae18c_z.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "pretrained_name = 'google/vit-base-patch16-224'\n",
    "# pretrained_name = 'vit-base-patch16-224-finetuned-imageneteval'\n",
    "# pretrained_name = 'openai/clip-vit-base-patch32'\n",
    "config = ViTConfig.from_pretrained(pretrained_name)\n",
    "processor = ViTImageProcessor.from_pretrained(pretrained_name)\n",
    "# get mean and std to unnormalize the processed images\n",
    "mean, std = processor.image_mean, processor.image_std\n",
    "\n",
    "pred_model = ViTForImageClassification.from_pretrained(pretrained_name)\n",
    "pred_model.to(device)\n",
    "# set to eval mode\n",
    "pred_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs.to(device)\n",
    "    outputs = pred_model(**inputs, output_hidden_states=True)\n",
    "    logits = outputs.logits\n",
    "    # model predicts one of the 1000 ImageNet classes\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    print(\"Predicted class:\", pred_model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
